print(df['emotion'].value_counts())

ax = df['emotion'].value_counts().plot(kind='bar',figsize=(4,4),title="emotion Count")
ax.set_xlabel("Emotions")
ax.set_ylabel("count")
plt.show()

fig = plt.figure(figsize=(6,4))
signal,sr=librosa.load("/content/drive/MyDrive/SpeechEmotion/Actor_18/03-01-01-01-01-01-18.wav",sr=22050)
librosa.display.waveplot(signal,sr=22050)

audio_signals=[]
for i in Emotions.values():
    audio_signals.append(df[df['emotion']==i]['path'].reset_index(drop=True)[0])
audio_signals

fig,axes=plt.subplots(4,2,figsize=(16,20))

for ax,emotion,path in zip(axes.flatten(),Emotions.values(),audio_signals):
    signal,sr=librosa.load(path,sr=22050)
    librosa.display.waveplot(signal,sr=22050,ax=ax)
    ax.set(title=emotion)

s,sr = librosa.load("/content/drive/MyDrive/SpeechEmotion/Actor_01/03-01-01-01-01-01-01.wav",sr = 22050)
ipd.display(ipd.Audio(s,rate=22050))


s,sr = librosa.load("/content/drive/MyDrive/SpeechEmotion/Actor_02/03-01-01-01-01-01-02.wav",sr = 22050)
ipd.display(ipd.Audio(s,rate=22050))

k,sr = librosa.load("/content/drive/MyDrive/SpeechEmotion/Actor_02/03-01-01-01-01-01-02.wav",sr = None)
ipd.display(ipd.Audio(k,rate = 10000))


for emotion,path in zip(Emotions.values(),audio_signals):
    signal,sr=librosa.load(path,sr=3000)
    print("Emotion : " + emotion)
    ipd.display(ipd.Audio(signal,rate=3000))

x,sr = librosa.load("/content/drive/MyDrive/SpeechEmotion/Actor_01/03-01-01-01-01-01-01.wav",sr = 22050)
mfccs = librosa.feature.mfcc(x, sr=sr)
print(mfccs.shape)

df1 = pd.DataFrame(columns=['feature'])
df1

bookmark=0

for index,y in tqdm(df.iterrows()):
        X, sample_rate = librosa.load(y['path'],res_type='kaiser_fast',sr=22050*2)
        sample_rate = np.array(sample_rate)
        result = np.array([])
        stft = np.abs(librosa.stft(X))

        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13).T,axis=0)
        result = np.hstack((result,mfccs))

        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)
        result = np.hstack((result,chroma))

        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)
        result = np.hstack((result,mel))

        feature = result
        #df.loc[df.index == index,'new_col'] = pd.Series(feature)
        df1.loc[bookmark] = [feature]
        #print(len(feature))
        bookmark=bookmark+1

df1.head()

df2 = pd.DataFrame(df1['feature'].values.tolist())
df2.head()

newdf = pd.concat([df,df2],axis=1)
newdf.head()

newdf[newdf.isna().any(axis=1)]

newdf.isnull().values.any()

newdf=newdf.fillna(0)

newdf.isnull().values.any()

X = newdf.iloc[:, 2:154]
X

Y = newdf.iloc[:,[1]]
Y

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

X_train = np.array(X_train)
Y_train = np.array(Y_train)
X_test = np.array(X_test)
Y_test = np.array(Y_test)

lb = LabelEncoder()

Y_train = np_utils.to_categorical(lb.fit_transform(Y_train))
Y_test = np_utils.to_categorical(lb.fit_transform(Y_test))

Y_train.shape

Y_test.shape

from sklearn.neural_network import MLPClassifier

model = MLPClassifier(alpha = 0.01,batch_size=256,epsilon=1e-08,hidden_layer_sizes=(300,),learning_rate='adaptive',max_iter=500)

model.fit(X_train,Y_train)

from sklearn.metrics import accuracy_score

y_pred = model.predict(X_test)
print(accuracy_score(y_true=Y_test,y_pred=y_pred)*100)

X_train = np.expand_dims(X_train, axis=2)
X_test = np.expand_dims(X_test, axis=2)

X_train.shape

X_test.shape

#Model Creation

model = Sequential()

model.add(Conv1D(216, 5,padding='same',input_shape=(152,1)))
model.add(Activation('relu'))
model.add(MaxPooling1D(pool_size=(8)))
model.add(Conv1D(128, 5,padding='same'))
model.add(Activation('relu'))
model.add(Dropout(0.1))
model.add(Conv1D(128, 5,padding='same',))
model.add(Activation('relu'))
model.add(Conv1D(256, 5,padding='same',))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(8))
model.add(Activation('softmax'))
opt = tensorflow.keras.optimizers.RMSprop(learning_rate = 0.00001, decay=1e-6)

model.summary()

model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])

mod = model.fit(X_train, Y_train, batch_size=32,epochs = 250, validation_data=(X_test, Y_test))

plt.plot(mod.history['loss'])
plt.plot(mod.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

model.evaluate(X_test, Y_test, verbose=0)
